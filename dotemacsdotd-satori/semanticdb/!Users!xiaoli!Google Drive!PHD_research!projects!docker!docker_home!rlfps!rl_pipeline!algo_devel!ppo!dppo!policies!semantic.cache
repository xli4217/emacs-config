;; Object policies/
;; SEMANTICDB Tags save file
(semanticdb-project-database-file "policies/"
  :tables
  (list
    (semanticdb-table "mlp_policy.py"
      :major-mode 'python-mode
      :tags 
        '( ("numpy" include nil nil [1 19])
            ("tensorflow" include nil nil [20 43])
            ("os" include nil nil [44 53])
            ("MlpPolicy" type
               (:members 
                  ( ("__init__" function
                       (:suite 
                          ( ("self" variable nil (reparse-symbol indented_block_body) [147 167])
                            ("self" variable nil (reparse-symbol indented_block_body) [176 207])
                            ("self" variable nil (reparse-symbol indented_block_body) [260 289])
                            ("self" variable nil (reparse-symbol indented_block_body) [347 384])
                            ("self" variable nil (reparse-symbol indented_block_body) [393 434])
                            ("self" variable nil (reparse-symbol indented_block_body) [443 492])
                            ("self" variable nil (reparse-symbol indented_block_body) [501 536])
                            ("self" variable nil (reparse-symbol indented_block_body) [545 579])
                            ("self" variable nil (reparse-symbol indented_block_body) [588 637])
                            ("self" variable nil (reparse-symbol indented_block_body) [646 695])
                            ("self" variable nil (reparse-symbol indented_block_body) [704 720])
                            ("self" variable nil (reparse-symbol indented_block_body) [738 770])
                            ("self" variable nil (reparse-symbol indented_block_body) [779 820])
                            ("self" variable nil (reparse-symbol indented_block_body) [829 864])
                            ("self" variable nil (reparse-symbol indented_block_body) [873 908])
                            ("self" code nil (reparse-symbol indented_block_body) [919 938])
                            ("self" variable nil (reparse-symbol indented_block_body) [947 978])
                            ("self" variable nil (reparse-symbol indented_block_body) [1128 1148])
                            ("if" code nil (reparse-symbol indented_block_body) [1157 1328]))                          
                        :parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [91 95])
                            ("config" variable nil (reparse-symbol function_parameters) [97 103])
                            ("sess" variable nil (reparse-symbol function_parameters) [105 109])
                            ("logger" variable nil (reparse-symbol function_parameters) [111 117])
                            ("deploy" variable nil (reparse-symbol function_parameters) [124 130]))                          
                        :constructor-flag t)
                        (reparse-symbol indented_block_body) [78 1328])
                    ("save" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [1358 1362])
                            ("model_dir" variable nil (reparse-symbol function_parameters) [1364 1373])
                            ("model_name" variable nil (reparse-symbol function_parameters) [1375 1385]))                          )
                        (reparse-symbol indented_block_body) [1349 1468])
                    ("restore" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [1485 1489])
                            ("model_dir" variable nil (reparse-symbol function_parameters) [1491 1500]))                          )
                        (reparse-symbol indented_block_body) [1473 1580])
                    ("_build_graph" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [1610 1614]))                          )
                        (reparse-symbol indented_block_body) [1593 2182])
                    ("_build_tensorboard_summary" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [2230 2234]))                          )
                        (reparse-symbol indented_block_body) [2199 2517])
                    ("_placeholders" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [2540 2544]))                          
                        :documentation " Input placeholders")
                        (reparse-symbol indented_block_body) [2522 3374])
                    ("_policy_nn" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [3394 3398]))                          
                        :documentation " Neural net for policy approximation function

        Policy parameterized by Gaussian means and variances. NN outputs mean
         action based on observation. Trainable variables hold log-variances
         for each action dimension (i.e. variances not determined by NN).
        ")
                        (reparse-symbol indented_block_body) [3379 5673])
                    ("_logprob" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [5691 5695]))                          
                        :documentation " Calculate log probabilities of a batch of observations & actions

        Calculates log probabilities using previous step's model parameters and
        new parameters being trained.
        ")
                        (reparse-symbol indented_block_body) [5678 6386])
                    ("_kl_entropy" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [6407 6411]))                          
                        :documentation "
        Add to Graph:
            1. KL divergence between old and new distributions
            2. Entropy of present policy given states and actions

        https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Kullback.E2.80.93Leibler_divergence
        https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Entropy
        ")
                        (reparse-symbol indented_block_body) [6391 7430])
                    ("_sample" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [7447 7451]))                          
                        :documentation " Sample from distribution, given observation ")
                        (reparse-symbol indented_block_body) [7435 7682])
                    ("_deterministic_action" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [7713 7717]))                          )
                        (reparse-symbol indented_block_body) [7687 7865])
                    ("_loss_train_op" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [7897 7901]))                          
                        :documentation "
        Three loss terms:
            1) standard policy gradient
            2) D_KL(pi_old || pi_new)
            3) Hinge loss on [D_KL - kl_targ]^2

        See: https://arxiv.org/pdf/1707.02286.pdf
        ")
                        (reparse-symbol indented_block_body) [7878 8544])
                    ("_init_session" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [8567 8571]))                          
                        :documentation "Launch TensorFlow session and initialize variables")
                        (reparse-symbol indented_block_body) [8549 8747])
                    ("get_action" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [8783 8787])
                            ("obs" variable nil (reparse-symbol function_parameters) [8789 8792])
                            ("deterministic" variable nil (reparse-symbol function_parameters) [8794 8807]))                          
                        :documentation "get action from distribution")
                        (reparse-symbol indented_block_body) [8768 9185])
                    ("update" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [9201 9205])
                            ("observes" variable nil (reparse-symbol function_parameters) [9207 9215])
                            ("actions" variable nil (reparse-symbol function_parameters) [9217 9224])
                            ("advantages" variable nil (reparse-symbol function_parameters) [9226 9236])
                            ("itr" variable nil (reparse-symbol function_parameters) [9238 9241]))                          
                        :documentation " Update policy based on observations, actions and advantages

        Args:
            observes: observations, shape = (N, obs_dim)
            actions: actions, shape = (N, act_dim)
            advantages: advantages, shape = (N,)
            logger: Logger object, see utils.py
        ")
                        (reparse-symbol indented_block_body) [9190 11634])
                    ("close_sess" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [11673 11677]))                          
                        :documentation " Close TensorFlow session ")
                        (reparse-symbol indented_block_body) [11658 11746]))                  
                :type "class")
                nil [55 11746])
            ("feed_dict" variable nil nil [8867 8897])
            ("if" code nil nil [8907 9163])
            ("return" code nil nil [9171 9184])
            ("\"\"\" Update policy based on observations, actions and advantages

        Args:
            observes: observations, shape = (N, obs_dim)
            actions: actions, shape = (N, act_dim)
            advantages: advantages, shape = (N,)
            logger: Logger object, see utils.py
        \"\"\"" code nil nil [9252 9547])
            ("feed_dict" variable nil nil [9556 9840])
            ("old_means_np, old_log_vars_np" code nil nil [9849 9988])
            ("feed_dict" variable nil nil [9997 10046])
            ("feed_dict" variable nil nil [10055 10098])
            ("loss, kl, entropy" code nil nil [10107 10134])
            ("for" code nil nil [10143 10498])
            ("if" code nil nil [10589 11045])
            ("if" code nil nil [11074 11634])
            ("\"\"\" Close TensorFlow session \"\"\"" code nil nil [11688 11720]))          
      :file "mlp_policy.py"
      :pointmax 11746
      :fsize 11745
      :lastmodtime '(23180 41941 0 0)
      :unmatched-syntax nil))
  :file "!Users!xiaoli!Google Drive!PHD_research!projects!docker!docker_home!rlfps!rl_pipeline!algo_devel!ppo!dppo!policies!semantic.cache"
  :semantic-tag-version "2.0"
  :semanticdb-version "2.2")
