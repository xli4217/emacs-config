;; Object traj_opt/
;; SEMANTICDB Tags save file
(semanticdb-project-database-file "traj_opt/"
  :tables
  (list
    (semanticdb-table "traj_opt_lqr.py"
      :major-mode 'python-mode
      :tags 
        '( ("\"\"\" This file interfaces to C++ iLQG-based trajectory optimization. \"\"\"" code nil nil [1 72])
            ("gps.algorithm.traj_opt.traj_opt" include nil nil [73 124])
            ("TrajOptLQR" type
               (:documentation " LQR trajectory optimization. "
                :superclasses ("TrajOpt")
                :members 
                  ( ("__init__" function
                       (:suite 
                          ( ("TrajOpt" code nil (reparse-symbol indented_block_body) [250 295]))                          
                        :parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [212 216])
                            ("hyperparams" variable nil (reparse-symbol function_parameters) [218 229])
                            ("dynamics" variable nil (reparse-symbol function_parameters) [231 239]))                          
                        :constructor-flag t)
                        (reparse-symbol indented_block_body) [199 296])
                    ("update" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [312 316]))                          
                        :documentation " Update trajectory distributions. ")
                        (reparse-symbol indented_block_body) [301 508]))                  
                :type "class")
                nil [127 508]))          
      :file "traj_opt_lqr.py"
      :pointmax 508
      :fsize 507
      :lastmodtime '(22606 11078 0 0)
      :unmatched-syntax nil)
    (semanticdb-table "traj_opt_lqr_python.py"
      :major-mode 'python-mode
      :tags 
        '( ("\"\"\" This file defines code for iLQG-based trajectory optimization. \"\"\"" code nil nil [1 71])
            ("logging" include nil nil [72 86])
            ("copy" include nil nil [87 98])
            ("numpy" include nil nil [100 118])
            ("numpy.linalg" include nil nil [119 155])
            ("scipy" include nil nil [156 174])
            ("gps.algorithm.traj_opt.config" include nil nil [176 230])
            ("gps.algorithm.traj_opt.traj_opt" include nil nil [231 282])
            ("gps.algorithm.traj_opt.traj_opt_utils" include nil nil [283 370])
            ("gps.algorithm.algorithm_badmm" include nil nil [372 428])
            ("gps.algorithm.algorithm_mdgps" include nil nil [429 485])
            ("LOGGER" variable nil nil [487 523])
            ("TrajOptLQRPython" type
               (:documentation " LQR trajectory optimization, Python implementation. "
                :superclasses ("TrajOpt")
                :members 
                  ( ("__init__" function
                       (:suite 
                          ( ("config" variable nil (reparse-symbol indented_block_body) [667 703])
                            ("config" code nil (reparse-symbol indented_block_body) [712 738])
                            ("TrajOpt" code nil (reparse-symbol indented_block_body) [748 778]))                          
                        :parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [639 643])
                            ("hyperparams" variable nil (reparse-symbol function_parameters) [645 656]))                          
                        :constructor-flag t)
                        (reparse-symbol indented_block_body) [626 779])
                    ("update" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [1171 1175])
                            ("m" variable nil (reparse-symbol function_parameters) [1177 1178])
                            ("algorithm" variable nil (reparse-symbol function_parameters) [1180 1189]))                          
                        :documentation " Run dual gradient decent to optimize trajectories. ")
                        (reparse-symbol indented_block_body) [1160 4036])
                    ("estimate_cost" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [4059 4063])
                            ("traj_distr" variable nil (reparse-symbol function_parameters) [4065 4075])
                            ("traj_info" variable nil (reparse-symbol function_parameters) [4077 4086]))                          
                        :documentation " Compute Laplace approximation to expected cost. ")
                        (reparse-symbol indented_block_body) [4041 4851])
                    ("forward" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [4868 4872])
                            ("traj_distr" variable nil (reparse-symbol function_parameters) [4874 4884])
                            ("traj_info" variable nil (reparse-symbol function_parameters) [4886 4895]))                          
                        :documentation "
        Perform LQR forward pass. Computes state-action marginals from
        dynamics and policy.
        Args:
            traj_distr: A linear Gaussian policy object.
            traj_info: A TrajectoryInfo object.
        Returns:
            mu: A T x dX mean action vector.
            sigma: A T x dX x dX covariance matrix.
        ")
                        (reparse-symbol indented_block_body) [4856 6888])
                    ("backward" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [6906 6910])
                            ("prev_traj_distr" variable nil (reparse-symbol function_parameters) [6912 6927])
                            ("traj_info" variable nil (reparse-symbol function_parameters) [6929 6938])
                            ("eta" variable nil (reparse-symbol function_parameters) [6940 6943])
                            ("algorithm" variable nil (reparse-symbol function_parameters) [6945 6954])
                            ("m" variable nil (reparse-symbol function_parameters) [6956 6957]))                          
                        :documentation "
        Perform LQR backward pass. This computes a new linear Gaussian
        policy object.
        Args:
            prev_traj_distr: A linear Gaussian policy object from
                previous iteration.
            traj_info: A TrajectoryInfo object.
            eta: Dual variable.
            algorithm: Algorithm object needed to compute costs.
            m: Condition number.
        Returns:
            traj_distr: A new linear Gaussian policy.
            new_eta: The updated dual variable. Updates happen if the
                Q-function is not PD.
        ")
                        (reparse-symbol indented_block_body) [6893 11721]))                  
                :type "class")
                nil [525 11721]))          
      :file "traj_opt_lqr_python.py"
      :pointmax 11721
      :fsize 11720
      :lastmodtime '(22606 62271 0 0)
      :unmatched-syntax nil)
    (semanticdb-table "traj_opt_pi2.py"
      :major-mode 'python-mode
      :tags 
        '( ("\"\"\" This file defines code for PI2-based trajectory optimization.

Optimization of trajectories with PI2 and a REPS-like KL-divergence constraint. 
References:
[1] E. Theodorou, J. Buchli, and S. Schaal. A generalized path integral control 
    approach to reinforcement learning. JMLR, 11, 2010.
[2] F. Stulp and O. Sigaud. Path integral policy improvement with covariance 
    matrix adaptation. In ICML, 2012.
[3] J. Peters, K. Mulling, and Y. Altun. Relative entropy policy search. 
    In AAAI, 2010.
 \"\"\"" code nil nil [1 511])
            ("copy" include nil nil [512 523])
            ("numpy" include nil nil [524 542])
            ("scipy" include nil nil [543 561])
            ("theano.tensor" include nil nil [563 588])
            ("theano" include nil nil [589 602])
            ("numpy.linalg" include nil nil [604 640])
            ("scipy.optimize" include nil nil [641 676])
            ("gps.algorithm.traj_opt.config" include nil nil [678 732])
            ("gps.algorithm.traj_opt.traj_opt" include nil nil [733 784])
            ("TrajOptPi2" type
               (:documentation " PI2 trajectory optimization.
    Hyperparameters:
        kl_threshold: KL-divergence threshold between old and new policies.
        covariance_damping: If greater than zero, covariance is computed as a
            multiple of the old covariance. Multiplier is taken to the power
            (1 / covariance_damping). If greater than one, slows down 
            convergence and keeps exploration noise high for more iterations.
        min_temperature: Minimum bound of the temperature optimiztion for the 
            soft-max probabilities of the policy samples.
    "
                :superclasses ("TrajOpt")
                :members 
                  ( ("__init__" function
                       (:suite 
                          ( ("config" variable nil (reparse-symbol indented_block_body) [1441 1477])
                            ("config" code nil (reparse-symbol indented_block_body) [1486 1512])
                            ("TrajOpt" code nil (reparse-symbol indented_block_body) [1521 1551])
                            ("self" variable nil (reparse-symbol indented_block_body) [1560 1614])
                            ("self" variable nil (reparse-symbol indented_block_body) [1623 1689])
                            ("self" variable nil (reparse-symbol indented_block_body) [1698 1758])
                            ("self" variable nil (reparse-symbol indented_block_body) [1783 1844])
                            ("self" variable nil (reparse-symbol indented_block_body) [2061 2159])
                            ("self" variable nil (reparse-symbol indented_block_body) [2168 2262])
                            ("self" variable nil (reparse-symbol indented_block_body) [2272 2307]))                          
                        :parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [1413 1417])
                            ("hyperparams" variable nil (reparse-symbol function_parameters) [1419 1430]))                          
                        :constructor-flag t)
                        (reparse-symbol indented_block_body) [1400 2308])
                    ("update" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [2324 2328])
                            ("m" variable nil (reparse-symbol function_parameters) [2330 2331])
                            ("algorithm" variable nil (reparse-symbol function_parameters) [2333 2342]))                          
                        :documentation "
        Perform optimization of the feedforward controls of time-varying
        linear-Gaussian controllers with PI2. 
        Args:
            m: Current condition number.
            algorithm: Currently used algorithm.
        Returns:
            traj_distr: Updated linear-Gaussian controller.
        ")
                        (reparse-symbol indented_block_body) [2313 4365])
                    ("update_pi2" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [4385 4389])
                            ("samples" variable nil (reparse-symbol function_parameters) [4410 4417])
                            ("mean_old" variable nil (reparse-symbol function_parameters) [4465 4473])
                            ("cov_old" variable nil (reparse-symbol function_parameters) [4494 4501])
                            ("X" variable nil (reparse-symbol function_parameters) [4522 4523]))                          
                        :documentation "
        Perform optimization with PI2. Computes new mean and covariance matrices
        of the policy parameters given policy samples and their costs.
        Args:
            samples: Matrix of policy samples with dimensions: 
                     [num_samples x num_timesteps x num_controls].
            costs: Matrix of roll-out costs with dimensions:
                   [num_samples x num_timesteps]
            mean_old: Old policy mean.
            cov_old: Old policy covariance.            
        Returns:
            mean_new: New policy mean.
            cov_new: New policy covariance.
            inv_cov_new: Inverse of the new policy covariance.
            chol_cov_new: Cholesky decomposition of the new policy covariance.
        ")
                        (reparse-symbol indented_block_body) [4370 8668])
                    ("kl_dual" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [8685 8689])
                            ("eta" variable nil (reparse-symbol function_parameters) [8691 8694])
                            ("kl_threshold" variable nil (reparse-symbol function_parameters) [8696 8708])
                            ("costs" variable nil (reparse-symbol function_parameters) [8710 8715]))                          
                        :documentation "
        Dual function for optimizing the temperature eta according to the given
        KL-divergence constraint.
        
        Args:
            eta: Temperature that has to be optimized.
            kl_threshold: Max. KL-divergence constraint.
            costs: Roll-out costs.            
        Returns:
            Value of the dual function.
        ")
                        (reparse-symbol indented_block_body) [8673 9241])
                    ("forward" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [9269 9273])
                            ("traj_distr" variable nil (reparse-symbol function_parameters) [9275 9285])
                            ("traj_info" variable nil (reparse-symbol function_parameters) [9287 9296]))                          
                        :documentation "
        Perform forward pass. Computes state-action marginals from
        dynamics and policy.
        Args:
            traj_distr: A linear Gaussian policy object.
            traj_info: A TrajectoryInfo object.
        Returns:
            mu: A T x dX mean action vector.
            sigma: A T x dX x dX covariance matrix.
        ")
                        (reparse-symbol indented_block_body) [9257 11285])
                    ("get_eventually_tltl_function" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [11343 11347])
                            ("targets" variable nil (reparse-symbol function_parameters) [11349 11356])
                            ("alpha" variable nil (reparse-symbol function_parameters) [11358 11363]))                          )
                        (reparse-symbol indented_block_body) [11310 11850])
                    ("get_then_tltl_function" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [11893 11897])
                            ("targets" variable nil (reparse-symbol function_parameters) [11899 11906])
                            ("alpha" variable nil (reparse-symbol function_parameters) [11908 11913])
                            ("s_or_l" variable nil (reparse-symbol function_parameters) [11920 11926]))                          )
                        (reparse-symbol indented_block_body) [11866 14634]))                  
                :type "class")
                nil [786 14634]))          
      :file "traj_opt_pi2.py"
      :pointmax 14643
      :fsize 14642
      :lastmodtime '(22652 15401 0 0)
      :unmatched-syntax nil)
    (semanticdb-table "traj_opt_pi2_with_feedback_update.py"
      :major-mode 'python-mode
      :tags 
        '( ("\"\"\" This file defines code for PI2-based trajectory optimization.

Optimization of trajectories with PI2 and a REPS-like KL-divergence constraint. 
References:
[1] E. Theodorou, J. Buchli, and S. Schaal. A generalized path integral control 
    approach to reinforcement learning. JMLR, 11, 2010.
[2] F. Stulp and O. Sigaud. Path integral policy improvement with covariance 
    matrix adaptation. In ICML, 2012.
[3] J. Peters, K. Mulling, and Y. Altun. Relative entropy policy search. 
    In AAAI, 2010.
 \"\"\"" code nil nil [1 511])
            ("copy" include nil nil [512 523])
            ("numpy" include nil nil [524 542])
            ("scipy" include nil nil [543 561])
            ("theano.tensor" include nil nil [563 588])
            ("theano" include nil nil [589 602])
            ("numpy.linalg" include nil nil [604 640])
            ("scipy.optimize" include nil nil [641 676])
            ("gps.algorithm.traj_opt.config" include nil nil [678 732])
            ("gps.algorithm.traj_opt.traj_opt" include nil nil [733 784])
            ("TrajOptPi2" type
               (:documentation " PI2 trajectory optimization.
    Hyperparameters:
        kl_threshold: KL-divergence threshold between old and new policies.
        covariance_damping: If greater than zero, covariance is computed as a
            multiple of the old covariance. Multiplier is taken to the power
            (1 / covariance_damping). If greater than one, slows down 
            convergence and keeps exploration noise high for more iterations.
        min_temperature: Minimum bound of the temperature optimiztion for the 
            soft-max probabilities of the policy samples.
    "
                :superclasses ("TrajOpt")
                :members 
                  ( ("__init__" function
                       (:suite 
                          ( ("config" variable nil (reparse-symbol indented_block_body) [1441 1477])
                            ("config" code nil (reparse-symbol indented_block_body) [1486 1512])
                            ("TrajOpt" code nil (reparse-symbol indented_block_body) [1521 1551])
                            ("self" variable nil (reparse-symbol indented_block_body) [1560 1614])
                            ("self" variable nil (reparse-symbol indented_block_body) [1623 1689])
                            ("self" variable nil (reparse-symbol indented_block_body) [1698 1758])
                            ("self" variable nil (reparse-symbol indented_block_body) [1783 1844])
                            ("self" variable nil (reparse-symbol indented_block_body) [2061 2159])
                            ("self" variable nil (reparse-symbol indented_block_body) [2168 2262])
                            ("self" variable nil (reparse-symbol indented_block_body) [2272 2307]))                          
                        :parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [1413 1417])
                            ("hyperparams" variable nil (reparse-symbol function_parameters) [1419 1430]))                          
                        :constructor-flag t)
                        (reparse-symbol indented_block_body) [1400 2308])
                    ("update" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [2324 2328])
                            ("m" variable nil (reparse-symbol function_parameters) [2330 2331])
                            ("algorithm" variable nil (reparse-symbol function_parameters) [2333 2342]))                          
                        :documentation "
        Perform optimization of the feedforward conrols of time-varying
        linear-Gaussian controllers with PI2. 
        Args:
            m: Current condition number.
            algorithm: Currently used algorithm.
        Returns:
            traj_distr: Updated linear-Gaussian controller.
        ")
                        (reparse-symbol indented_block_body) [2313 4364])
                    ("update_pi2" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [4384 4388])
                            ("samples" variable nil (reparse-symbol function_parameters) [4409 4416])
                            ("mean_old" variable nil (reparse-symbol function_parameters) [4464 4472])
                            ("cov_old" variable nil (reparse-symbol function_parameters) [4493 4500])
                            ("X" variable nil (reparse-symbol function_parameters) [4521 4522]))                          
                        :documentation "
        Perform optimization with PI2. Computes new mean and covariance matrices
        of the policy parameters given policy samples and their costs.
        Args:
            samples: Matrix of policy samples with dimensions: 
                     [num_samples x num_timesteps x num_controls].
            costs: Matrix of roll-out costs with dimensions:
                   [num_samples x num_timesteps]
            mean_old: Old policy mean.
            cov_old: Old policy covariance.            
        Returns:
            mean_new: New policy mean.
            cov_new: New policy covariance.
            inv_cov_new: Inverse of the new policy covariance.
            chol_cov_new: Cholesky decomposition of the new policy covariance.
        ")
                        (reparse-symbol indented_block_body) [4369 8630])
                    ("kl_dual" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [8647 8651])
                            ("eta" variable nil (reparse-symbol function_parameters) [8653 8656])
                            ("kl_threshold" variable nil (reparse-symbol function_parameters) [8658 8670])
                            ("costs" variable nil (reparse-symbol function_parameters) [8672 8677]))                          
                        :documentation "
        Dual function for optimizing the temperature eta according to the given
        KL-divergence constraint.
        
        Args:
            eta: Temperature that has to be optimized.
            kl_threshold: Max. KL-divergence constraint.
            costs: Roll-out costs.            
        Returns:
            Value of the dual function.
        ")
                        (reparse-symbol indented_block_body) [8635 9203])
                    ("forward" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [9231 9235])
                            ("traj_distr" variable nil (reparse-symbol function_parameters) [9237 9247])
                            ("traj_info" variable nil (reparse-symbol function_parameters) [9249 9258]))                          
                        :documentation "
        Perform forward pass. Computes state-action marginals from
        dynamics and policy.
        Args:
            traj_distr: A linear Gaussian policy object.
            traj_info: A TrajectoryInfo object.
        Returns:
            mu: A T x dX mean action vector.
            sigma: A T x dX x dX covariance matrix.
        ")
                        (reparse-symbol indented_block_body) [9219 11247])
                    ("get_eventually_tltl_function" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [11305 11309])
                            ("targets" variable nil (reparse-symbol function_parameters) [11311 11318])
                            ("alpha" variable nil (reparse-symbol function_parameters) [11320 11325]))                          )
                        (reparse-symbol indented_block_body) [11272 11812])
                    ("get_then_tltl_function" function
                       (:parent "dummy"
                        :arguments 
                          ( ("self" variable nil (reparse-symbol function_parameters) [11855 11859])
                            ("targets" variable nil (reparse-symbol function_parameters) [11861 11868])
                            ("alpha" variable nil (reparse-symbol function_parameters) [11870 11875])
                            ("s_or_l" variable nil (reparse-symbol function_parameters) [11882 11888]))                          )
                        (reparse-symbol indented_block_body) [11828 14596]))                  
                :type "class")
                nil [786 14596]))          
      :file "traj_opt_pi2_with_feedback_update.py"
      :pointmax 14605
      :fsize 14604
      :lastmodtime '(22638 53414 0 0)
      :unmatched-syntax nil))
  :file "!Users!xiaoli!Dropbox!PHD_research!projects!RLFPS!rlfps!gps!algorithm!traj_opt!semantic.cache"
  :semantic-tag-version "2.0"
  :semanticdb-version "2.2")
